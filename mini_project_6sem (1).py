# -*- coding: utf-8 -*-
"""Mini_project_6sem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vNKhTIZ7zzs1vsMHoUjcAB7wmpMG9ahA
"""

# Upload kaggle.json again
from google.colab import files
uploaded = files.upload()  # Upload 'kaggle (1).json' again

# Rename it to kaggle.json regardless of its uploaded name
import os
for fname in uploaded.keys():
    os.rename(fname, "kaggle.json")

# Move to kaggle directory and set permissions
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the Chest X-ray Pneumonia dataset
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content

# Unzip it
!unzip -q /content/chest-xray-pneumonia.zip -d /content/dataset

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Paths to train, validation, and test directories
train_dir = "/content/dataset/chest_xray/train"
val_dir = "/content/dataset/chest_xray/val"
test_dir = "/content/dataset/chest_xray/test"

# Image size and batch size
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Create ImageDataGenerators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    zoom_range=0.1,
    horizontal_flip=True
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

# Load data from directories
train_data = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

val_data = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

test_data = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model

# Load the pre-trained MobileNetV2 model without the top layer
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False  # Freeze base model

# Add custom layers on top
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.2)(x)
x = Dense(64, activation='relu')(x)
output = Dense(1, activation='sigmoid')(x)  # Binary classification

# Build final model
model = Model(inputs=base_model.input, outputs=output)

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()

from tensorflow.keras.callbacks import EarlyStopping

# Early stopping to prevent overfitting
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(
    train_data,
    epochs=10,
    validation_data=val_data,
    callbacks=[early_stop]
)

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Predict on test data
y_pred_probs = model.predict(test_data)
y_preds = (y_pred_probs > 0.5).astype("int32").flatten()
y_true = test_data.classes

# Confusion matrix
cm = confusion_matrix(y_true, y_preds)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=test_data.class_indices, yticklabels=test_data.class_indices)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Classification report
print("Classification Report:")
print(classification_report(y_true, y_preds, target_names=test_data.class_indices.keys()))

import cv2
import tensorflow.keras.backend as K
import tensorflow as tf # Make sure tensorflow is imported
import numpy as np

# Pick a random image from test set
img_path = test_data.filepaths[10]  # change index to try different images

# Load and preprocess the image
img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)
img_array = tf.keras.preprocessing.image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) / 255.0

# Get the model's prediction
pred = model.predict(img_array)[0][0]
pred_class = 'PNEUMONIA' if pred > 0.5 else 'NORMAL'

# Create a model that maps input image to activations + output
grad_model = tf.keras.models.Model([model.inputs], [model.get_layer('Conv_1_bn').output, model.output])

# Compute gradient of top predicted class with respect to last conv layer
with tf.GradientTape() as tape:
    conv_outputs, predictions = grad_model(img_array)
    loss = predictions[:, 0]

grads = tape.gradient(loss, conv_outputs)[0]
# Change here: Calculate mean across spatial dimensions only (1, 2)
pooled_grads = K.mean(grads, axis=(0, 1))
conv_outputs = conv_outputs[0]

# Multiply each channel by importance
heatmap = conv_outputs @ pooled_grads[..., tf.newaxis] # This line should now work
heatmap = tf.squeeze(heatmap)
heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)

# Resize and overlay heatmap on original image
heatmap = cv2.resize(heatmap.numpy(), IMG_SIZE)
heatmap = np.uint8(255 * heatmap)
heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

# Superimpose on original
original_img = cv2.imread(img_path)
original_img = cv2.resize(original_img, IMG_SIZE)
superimposed_img = cv2.addWeighted(original_img, 0.6, heatmap, 0.4, 0)

# Show result
plt.figure(figsize=(10,5))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))
plt.title(f"Original Image\n(Predicted: {pred_class})")

plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))
plt.title("Grad-CAM Heatmap")
plt.show()

# Save the trained model
model.save("pneumonia_detection_model.h5")
print("Model saved as pneumonia_detection_model.h5")

""".
.
.
.
"""